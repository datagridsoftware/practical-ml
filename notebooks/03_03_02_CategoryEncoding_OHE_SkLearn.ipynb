{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a998d796",
   "metadata": {},
   "source": [
    "### Feature engineering - CategoryEncoding - OneHotEncoder\n",
    "OneHotEncoder with sklearn on the Titanic dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59e093",
   "metadata": {},
   "source": [
    "***\n",
    "#### Environment\n",
    "`conda activate sklearn-env`\n",
    "\n",
    "***\n",
    "#### Goals\n",
    "- Replace categorical and discrete columns with categorical elements corespondng to each value from dataset\n",
    "- Note that name is not identified as a categorical value\n",
    "\n",
    "***\n",
    "#### References\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf2d4d",
   "metadata": {},
   "source": [
    "#### Basic python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6869af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e792d",
   "metadata": {},
   "source": [
    "#### Dataset load using sklearn API from https://www.openml.org site\n",
    "\n",
    "https://www.openml.org/d/40945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932de636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load data from https://www.openml.org/d/40945\n",
    "raw_dataset = fetch_openml(\"titanic\", version=1, as_frame=True).frame\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['boat', 'body', 'home.dest'],  axis=1, inplace=True)\n",
    "dataset = dataset.dropna().copy()\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505b855",
   "metadata": {},
   "source": [
    "### Verify categorical /discrete fields in dataset\n",
    "\n",
    "Notice:\n",
    "- `pclass` discrete fiels having 3 distinct values.\n",
    "- `sex` and `embarked` fields - categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e0507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder().fit(dataset[['pclass', 'sex', 'embarked']])\n",
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daec578",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_f = encoder.transform(dataset[['pclass', 'sex', 'embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077686a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_dataset = pd.DataFrame(ohe_f.todense())\n",
    "\n",
    "ohe_dataset.columns =['pclass_1', 'pclass_2', 'pclass_3', 'sex_F', 'sex_M', 'embarked_C', 'embarked_Q', 'embarked_S']\n",
    "\n",
    "# the 2 datasets must have the same indexes or this operation will introduce NaNs\n",
    "new_dataset = pd.concat([dataset, ohe_dataset], axis=1)\n",
    "\n",
    "new_dataset.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e850cb59",
   "metadata": {},
   "source": [
    "#### Predict and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a12419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def raw_dataset(df):\n",
    "    dataset = df[['age','sibsp','parch', 'fare', 'survived' ]].copy()\n",
    "    return dataset\n",
    "    \n",
    "def prepared_dataset(df):\n",
    "    dataset = df.copy().drop(['name', 'fare', 'ticket', 'cabin', 'pclass', 'sex', 'embarked'], axis='columns')\n",
    "    dataset[['age']] = MinMaxScaler().fit_transform(dataset[['age']])\n",
    "    dataset = dataset.copy().drop(['pclass_3', 'sex_M', 'embarked_S'], axis='columns')\n",
    "    return dataset\n",
    "\n",
    "def converge_error_dataset(df):\n",
    "    dataset = df.copy().drop(['name', 'ticket', 'sex', 'cabin', 'embarked'], axis='columns')\n",
    "    return dataset\n",
    "    \n",
    "#use the prepared data set\n",
    "dataset = prepared_dataset(new_dataset)\n",
    "\n",
    "#use the semi-prepared data set that will report converge errors\n",
    "#dataset = converge_error_dataset(new_dataset)\n",
    "\n",
    "#or use the raw dataset\n",
    "#dataset = raw_dataset(dataset)\n",
    "\n",
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('survived')\n",
    "test_labels = test_features.pop('survived')\n",
    "\n",
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dbf8e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regressor = LogisticRegression().fit(train_features, train_labels)\n",
    "\n",
    "scored_test = logistic_regressor.predict(test_features)\n",
    "scored_test_proba = logistic_regressor.predict_proba(test_features)\n",
    "test_dataset['predicted'] = scored_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0613cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_dataset['survived'], test_dataset['predicted'])\n",
    "print(\"Accuracy of the model is %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[['survived', 'predicted']].head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
