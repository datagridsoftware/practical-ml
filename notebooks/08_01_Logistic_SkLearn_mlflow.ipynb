{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4313799",
   "metadata": {},
   "source": [
    "### Cross validation for logistic regression\n",
    "Cross validation with sklearm for logistic regression on the Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b2108",
   "metadata": {},
   "source": [
    "***\n",
    "#### Environment\n",
    "`conda activate sklearn-env`\n",
    "\n",
    "\n",
    "Note: make sure that you have `mlflow` installed in your conda env. Check this by running:\n",
    "\n",
    "`pip list |grep mlflow`\n",
    "\n",
    "If result is zero you can install either by recreating the `sklearn-env` conda environment or by running \n",
    "\n",
    "`pip install mlflow`\n",
    "\n",
    "#### Goals\n",
    "- Build a pipeline\n",
    "- Use the pipeline to transform data\n",
    "- Use the pipeline to predict\n",
    "- Save model in local mlflow repository \n",
    "- Programatically load model and score it locally \n",
    "- Serve model from local repository and test scoring results via HTTP endpoint \n",
    "***\n",
    "#### References\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "https://www.mlflow.org\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61478e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pprint import pprint\n",
    "import mlflow\n",
    "\n",
    "# enable autologging\n",
    "mlflow.sklearn.autolog()\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fcc7b0",
   "metadata": {},
   "source": [
    "#### Dataset load from CSV located on UCI website.\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data  \n",
    "If the URL does not work the dataset can be loaded from the data folder `./data/auto-mpg.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa69154c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load data from https://www.openml.org/d/40945\n",
    "raw_dataset = fetch_openml(\"titanic\", version=1, as_frame=True).frame\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b34939",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['boat', 'body', 'home.dest', 'fare', 'cabin'],  axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0fb4f",
   "metadata": {},
   "source": [
    "### Dataset split\n",
    "- row base in test and train datasets\n",
    "- column base in features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=random.randint(0, 1000))\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('survived')\n",
    "test_labels = test_features.pop('survived')\n",
    "\n",
    "test_labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7973f31a",
   "metadata": {},
   "source": [
    "#### Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289963a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_features = ['age', 'sibsp', 'parch']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "custom_features = ['pclass']\n",
    "custom_transformer = FunctionTransformer(np.square, validate=True)\n",
    "\n",
    "categorical_features = ['embarked', 'sex']\n",
    "ohe_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', ohe_transformer)])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('ohe', categorical_transformer, categorical_features),\n",
    "        ('cust', custom_transformer, custom_features)])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LogisticRegression())])\n",
    "with mlflow.start_run(run_name='run_123') as run:\n",
    "    pipeline_model = pipeline.fit(train_features, train_labels)\n",
    "    print('Pipeline model :' +str( pipeline_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd32c954",
   "metadata": {},
   "source": [
    "#### Extract pipeline metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bad235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_logged_data(run_id):\n",
    "    pprint(\"RunId:\" + str(run_id))\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    data = client.get_run(run_id).data\n",
    "    tags = {k: v for k, v in data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in client.list_artifacts(run_id, \"model\")]\n",
    "    return data.params, data.metrics, tags, artifacts\n",
    "\n",
    "# fetch logged data\n",
    "params, metrics, tags, artifacts = fetch_logged_data(run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f706d2ee",
   "metadata": {},
   "source": [
    "#### Show captured params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f4741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display('Params', params)\n",
    "display('Metrics', metrics)\n",
    "display('Tags', tags)\n",
    "display('Artifacts', artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bde4c6",
   "metadata": {},
   "source": [
    "#### Load model and score it programatically from mlflow repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658300eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.sklearn.load_model('runs:/{}/model'.format(run.info.run_id))\n",
    "scored_data = model.predict(test_features)\n",
    "\n",
    "scored_data = pipeline.predict(test_features)\n",
    "scored_df = pd.DataFrame(data = scored_data)\n",
    "scored_df = pd.concat([scored_df, test_labels], axis=1)\n",
    "print('Scored DF: '+ str(scored_df.head(10)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10038f",
   "metadata": {},
   "source": [
    "#### Start mlflow UI and notice saved model along with it metadata (metrics , logs artifacts etc)\n",
    "Note: mlflow UI url is http://localhost:5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2314d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mlflow ui --port 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2679985",
   "metadata": {},
   "source": [
    "#### Start an `mlflow serve` instance to expose HTTP rest call for scoring\n",
    "Note: The following lines are disabled because ipython notebook can not run cells in parallel and previous cel \"hangs\" on `mlflow ui` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962beb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow models serve -m runs:/{run.info.run_id}/model --port 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ce674",
   "metadata": {},
   "source": [
    "#### Score loaded mode via http command line tool (`curl`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl -d '{\"columns\":[\"pclass\",\"name\",\"sex\",\"age\",\"sibsp\",\"parch\",\"ticket\",\"embarked\"], \"data\":[[1,\"Allen, Miss. Elisabeth Walton\",\"female\",29,0,0,\"24160\",\"S\"]]}' -H 'Content-Type: application/json; format=pandas-split' -X POST localhost:1234/invocations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
