{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8bc072",
   "metadata": {},
   "source": [
    "### Feature engineering - Scalers\n",
    "Standard Scaler with sklearn on the auto-mpg dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e5804",
   "metadata": {},
   "source": [
    "***\n",
    "#### Environment\n",
    "`conda activate sklearn-env`\n",
    "\n",
    "***\n",
    "#### Goals\n",
    "***\n",
    "- Replace continuous features with their scaled version\n",
    "\n",
    "***\n",
    "#### References\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156020dd",
   "metadata": {},
   "source": [
    "#### Basic python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5059ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random \n",
    "\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ea297",
   "metadata": {},
   "source": [
    "#### Dataset load from CSV located on UCI website.\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data  \n",
    "If the URL does not work the dataset can be loaded from the data folder `./data/auto-mpg.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset = pd.read_csv(url, names=column_names,\n",
    "                          na_values='?', comment='\\t',\n",
    "                          sep=' ', skipinitialspace=True)\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f956aa5",
   "metadata": {},
   "source": [
    "### Dataset split\n",
    "- row base in test and train datasets\n",
    "- column base in features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f935c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna().copy()[['MPG', 'Weight', 'Displacement', 'Acceleration', 'Model Year', 'Origin']]\n",
    "#[['MPG', 'Weight', 'Displacement', 'Acceleration', 'Model Year', 'Origin']]\n",
    "#[['MPG', 'Displacement', 'Acceleration', 'Model Year', 'Origin']]\n",
    "#[['MPG', 'Weight', 'Displacement', 'Model Year', 'Origin']]\n",
    "#[['MPG', 'Weight', 'Acceleration', 'Model Year', 'Origin']]\n",
    "#[['MPG', 'Weight']]\n",
    "\n",
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('MPG')\n",
    "test_labels = test_features.pop('MPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbeb90b",
   "metadata": {},
   "source": [
    "#### Standardization\n",
    "\n",
    "Centers features on 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c171edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler().fit(train_features)\n",
    "std_train_features = std_scaler.transform(train_features)\n",
    "std_test_features = std_scaler.transform(test_features)\n",
    "print(std_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde4e620",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Brings features in [0..1] interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e9ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "norm_scaler = MinMaxScaler().fit(train_features)\n",
    "norm_train_features = norm_scaler.transform(train_features)\n",
    "norm_test_features = norm_scaler.transform(test_features)\n",
    "print(norm_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07076389",
   "metadata": {},
   "source": [
    "#### Observe impact on convergence\n",
    "\n",
    "Train with 2 algorithms and 3 versions of the test data: raw, normalized, standardized. Observe impact of feature scaling on model convergence: \n",
    "\n",
    "- Ridge is an algorithm that uses GD so it benefits from standardized features\n",
    "- OLS does not use GD so feature scaling is irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def predictRidge(train, test, labels, col):\n",
    "    linear_regressor = Ridge(alpha=0.01, max_iter=1000, solver='saga').fit(train, labels)\n",
    "    print(\"Training with %s data converged in %d iterations\" % (col, linear_regressor.n_iter_))\n",
    "    scored_test = linear_regressor.predict(test)\n",
    "    test_dataset[col]=scored_test\n",
    "\n",
    "def predictOLS(train, test, labels, col):\n",
    "    linear_regressor = LinearRegression().fit(train, labels)\n",
    "    scored_test = linear_regressor.predict(test)\n",
    "    test_dataset[col]=scored_test\n",
    "\n",
    "predictRidge(train_features, test_features, train_labels, 'Ridge Raw')\n",
    "predictRidge(std_train_features, std_test_features, train_labels, 'Ridge Std')\n",
    "predictRidge(norm_train_features, norm_test_features, train_labels, 'Ridge Norm')\n",
    "\n",
    "predictOLS(train_features, test_features, train_labels, 'OLS Raw')\n",
    "predictOLS(std_train_features, std_test_features, train_labels, 'OLS Std')\n",
    "predictOLS(norm_train_features, norm_test_features, train_labels, 'OLS Norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be374c96",
   "metadata": {},
   "source": [
    "#### Observe impact on model quality\n",
    "\n",
    "Compute RMS for the models created in the previous step. Observe impact of feature scaling on model quality: \n",
    "- Ridge is an algorithm that uses regularization and so it requires features to be on the same scale for best results\n",
    "- OLS does not use regularization so feature scaling is irelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/prediction-intervals-for-machine-learning/\n",
    "from numpy import sum as arraysum\n",
    "from numpy import sqrt\n",
    "from numpy import mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def predictionInterval(y, y_pred, name):\n",
    "    sum_errs = arraysum((y - y_pred)**2)\n",
    "    stdev = sqrt(1/(len(y)-2) * sum_errs)\n",
    "    interval = 1.96 * stdev\n",
    "\n",
    "    print(\"Prediction interval for %s is %f\" % (name, interval))\n",
    "    print(\"RMSE for %s is %f\" % ( name, mean_squared_error(y, y_pred)))\n",
    "\n",
    "print(\"\\nRidge\")\n",
    "predictionInterval(test_dataset['MPG'], test_dataset['Ridge Raw'], 'Ridge Raw')\n",
    "predictionInterval(test_dataset['MPG'], test_dataset['Ridge Std'], 'Ridge Std')\n",
    "predictionInterval(test_dataset['MPG'], test_dataset['Ridge Norm'], 'Ridge Norm')\n",
    "\n",
    "print(\"\\nOLS\")\n",
    "predictionInterval(test_dataset['MPG'], test_dataset['OLS Raw'], 'OLS Raw')\n",
    "predictionInterval(test_dataset['MPG'], test_dataset['OLS Std'], 'OLS Std')\n",
    "predictionInterval(test_dataset['MPG'], test_dataset['OLS Norm'], 'OLS Norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ffc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
