{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f28a8c6",
   "metadata": {},
   "source": [
    "### Keras Example\n",
    "Logistic regression for structured data on the Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd33af",
   "metadata": {},
   "source": [
    "***\n",
    "#### Environment\n",
    "`conda activate tf-env`\n",
    "\n",
    "***\n",
    "#### Goals\n",
    "- Explore Tensorflow via Keras API\n",
    "\n",
    "***\n",
    "#### References\n",
    "\n",
    "https://keras.io/  \n",
    "https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c89a7",
   "metadata": {},
   "source": [
    "#### Basic python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba610e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d747c5",
   "metadata": {},
   "source": [
    "#### Dataset load using sklearn API from https://www.openml.org site\n",
    "\n",
    "https://www.openml.org/d/40945\n",
    "\n",
    "If the URL does not work the dataset can be loaded from the data folder `./data/titanic/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca68922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load data from https://www.openml.org/d/40945\n",
    "raw_dataset = fetch_openml(\"titanic\", version=1, as_frame=True).frame\n",
    "raw_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4bc343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical numeric columns pclass , sibsp and parch to int values\n",
    "# Drop un-used columns.\n",
    "raw_dataset.pclass = raw_dataset.pclass.astype(int)\n",
    "raw_dataset.sibsp = raw_dataset.sibsp.astype(int)\n",
    "raw_dataset.parch = raw_dataset.parch.astype(int)\n",
    "dataset = raw_dataset.copy().drop(columns=['name','ticket','cabin','boat', 'body', 'home.dest'])\n",
    "display(dataset.describe().transpose())\n",
    "display(dataset.info())\n",
    "display(dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39148e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NA\n",
    "dataset = dataset.dropna()\n",
    "#dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd67b6a1",
   "metadata": {},
   "source": [
    "### Prepare train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31532d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(dataset, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f723c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('survived').astype(int)\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adfaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "def get_normalization_layer(name, dataset):\n",
    "    # Create a Normalization layer for our feature.\n",
    "    normalizer = preprocessing.Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    # Create a StringLookup layer which will turn strings into integer indices\n",
    "    if dtype == 'string':\n",
    "        index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = preprocessing.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the set of possible values and assign them a fixed integer index.\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # Create a Discretization for our integer indices.\n",
    "    encoder = preprocessing.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "    # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "    # layer so we can use them, or include them in the functional model later.\n",
    "    return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_ds = df_to_dataset(train, shuffle=True, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))\n",
    "print('A batch of ages:', train_features['age'])\n",
    "print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e11326",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846ab66",
   "metadata": {},
   "source": [
    "### Build the pipeline components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48193cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numeric features.\n",
    "for header in ['age', 'fare']:\n",
    "    numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs.append(numeric_col)\n",
    "    encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1762c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Categorical features encoded as integers.\n",
    "int_categorical_col = ['pclass', 'sibsp', 'parch']\n",
    "for header in int_categorical_col:\n",
    "    numeric_cat_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "    encoding_layer = get_category_encoding_layer(header, train_ds, dtype='int64',\n",
    "                                             max_tokens=5)\n",
    "    encoded_numeric_cat_col = encoding_layer(numeric_cat_col)\n",
    "    all_inputs.append(numeric_cat_col)\n",
    "    encoded_features.append(encoded_numeric_cat_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abccd70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features encoded as string.\n",
    "categorical_cols = ['sex', 'embarked']\n",
    "for header in categorical_cols:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "    encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string',\n",
    "                                               max_tokens=5)\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59dae87",
   "metadata": {},
   "source": [
    "### Assemble the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(all_inputs, output)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a078186c",
   "metadata": {},
   "source": [
    "### Visualize the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209de2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rankdir='LR' is used to make the graph horizontal.\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91462cba",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5757bd2",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Loss\", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db51245",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadbbfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_titanic_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ab11e0",
   "metadata": {},
   "source": [
    "### Reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24949e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = tf.keras.models.load_model('my_keras_titanic_classifier')\n",
    "loss, accuracy = reloaded_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_survival(sample):\n",
    "    input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "    predictions = reloaded_model.predict(input_dict)\n",
    "    prob = tf.nn.sigmoid(predictions[0])\n",
    "    print( \"This person had a %.1f percent probability of survival.\" % (100 * prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd8d8b3",
   "metadata": {},
   "source": [
    "### Predict using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65487bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predict_survival({\n",
    "    'pclass': 1,\n",
    "    'sex': 'female',\n",
    "    'age': 7,\n",
    "    'sibsp': 1,\n",
    "    'parch': 2,\n",
    "    'fare': 39.4000,\n",
    "    'embarked': 'S'\n",
    "})\n",
    "\n",
    "predict_survival({\n",
    "    'pclass': 1,\n",
    "    'sex': 'male',\n",
    "    'age': 7,\n",
    "    'sibsp': 1,\n",
    "    'parch': 2,\n",
    "    'fare': 39.4000,\n",
    "    'embarked': 'S'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a070c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
