{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb164861",
   "metadata": {},
   "source": [
    "### Pipeline for logistic regression\n",
    "Pipeline for logistic regression with sklearn on the Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b69b7",
   "metadata": {},
   "source": [
    "***\n",
    "#### Environment\n",
    "`conda activate sklearn-env`\n",
    "\n",
    "***\n",
    "#### Goals\n",
    "- Build a pipeline\n",
    "- Use the pipeline to transform data\n",
    "- Use the pipeline to predict\n",
    "- Save in various formats, load and use it to score\n",
    "\n",
    "\n",
    "***\n",
    "#### References\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_persistence.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Basic python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26457c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff931e",
   "metadata": {},
   "source": [
    "#### Dataset load using sklearn API from https://www.openml.org site\n",
    "\n",
    "https://www.openml.org/d/40945\n",
    "\n",
    "If the URL does not work the dataset can be loaded from the data folder `./data/titanic/`. \n",
    "- `train.csv`\n",
    "- `test.csv`\n",
    "- `gender_submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25dc3c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load data from https://www.openml.org/d/40945\n",
    "raw_dataset = fetch_openml(\"titanic\", version=1, as_frame=True).frame\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['boat', 'body', 'home.dest', 'fare', 'cabin'],  axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139b86f",
   "metadata": {},
   "source": [
    "### Dataset split\n",
    "- row base in test and train datasets\n",
    "- column base in features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c12f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('survived')\n",
    "test_labels = test_features.pop('survived')\n",
    "\n",
    "test_labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f09d26",
   "metadata": {},
   "source": [
    "#### Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc3fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_features = ['age', 'sibsp', 'parch']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "custom_features = ['pclass']\n",
    "custom_transformer = FunctionTransformer(np.square, validate=True)\n",
    "\n",
    "categorical_features = ['embarked', 'sex']\n",
    "ohe_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', ohe_transformer)])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('ohe', categorical_transformer, categorical_features),\n",
    "        ('cust', custom_transformer, custom_features)])\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf621675",
   "metadata": {},
   "source": [
    "#### Use the pipeline to transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6b745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit_transform(train_features, train_labels)\n",
    "\n",
    "transformed_df = pd.DataFrame(data = pipeline_model)\n",
    "transformed_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18503a",
   "metadata": {},
   "source": [
    "#### Build the full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9927ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LogisticRegression())])\n",
    "pipeline_model = pipeline.fit(train_features, train_labels)\n",
    "print(pipeline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram')\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6fb020",
   "metadata": {},
   "source": [
    "#### Use pipeline to predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057937",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_data = pipeline.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ee4b7",
   "metadata": {},
   "source": [
    "#### Show predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b3a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_df = pd.DataFrame(data = scored_data)\n",
    "\n",
    "scored_df = pd.concat([scored_df, test_labels], axis=1)\n",
    "scored_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1f75e",
   "metadata": {},
   "source": [
    "### Save then load model in pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf3c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "s = pickle.dumps(pipeline)\n",
    "pipeline_new = pickle.loads(s)\n",
    "scored_test = pipeline_new.predict(test_features)\n",
    "scored_df = pd.DataFrame(data = scored_test)\n",
    "scored_df = pd.concat([scored_df, test_labels], axis=1)\n",
    "scored_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7171ac",
   "metadata": {},
   "source": [
    "### Alternative to python internal pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "    \n",
    "dump(pipeline, 'mypipeline.joblib') \n",
    "\n",
    "pipeline2 = load('mypipeline.joblib') \n",
    "\n",
    "scored_test = pipeline2.predict(test_features)\n",
    "scored_df = pd.DataFrame(data = scored_test)\n",
    "scored_df = pd.concat([scored_df, test_labels], axis=1)\n",
    "scored_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
